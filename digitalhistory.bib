@STRING{aha	= {American Historical Review} }
@STRING{jah	= {Journal of American History} }

@Book{		  arnold_humanities_2015,
  title		= {Humanities Data in R},
  isbn		= {978-3-319-20701-8 978-3-319-20702-5},
  url		= {http://link.springer.com/10.1007/978-3-319-20702-5},
  publisher	= {Springer},
  author	= {Arnold, Taylor and Tilton, Lauren},
  urldate	= {2016-08-23},
  date		= {2015},
  file		= {Arnold and Tilton - 2015 - Humanities Data in
		  R.pdf:/Users/lmullen/Zotero/storage/DSM765NP/Arnold and
		  Tilton - 2015 - Humanities Data in R.pdf:application/pdf}
}

@Article{	  aydelotte_quantification_1966,
  title		= {Quantification in {{History}}},
  volume	= {71},
  copyright	= {Copyright \textcopyright{} 1966 American Historical
		  Association},
  issn		= {0002-8762},
  doi		= {10.2307/1846023},
  number	= {3},
  journal	= {The American Historical Review},
  author	= {Aydelotte, William O.},
  month		= apr,
  year		= {1966},
  pages		= {803--825}
}

@Misc{		  ayers_pasts_1999,
  title		= {The {{Pasts}} and {{Futures}} of {{Digital History}}},
  publisher	= {{Virginia Center for Digital History}},
  author	= {Ayers, Edward L.},
  year		= {1999}
}

@TechReport{	  ayershistoryhypertext1999a,
  title		= {History in {{Hypertext}}},
  institution	= {{University of Virginia}},
  author	= {Ayers, Edward L.},
  year		= {1999},
  file		= {/Users/jasonheppler/Dropbox/research-papers/Ayers_1999_History
		  in Hypertext.pdf}
}

@Article{	  ayerspastsfuturesdigital1999b,
  title		= {The {{Pasts}} and {{Futures}} of {{Digital History}}},
  lccn		= {0020},
  author	= {Ayers, Edward L.},
  year		= {1999}
}

@Book{		  barzun_clio_1974,
  title		= {Clio and the Doctors : Psycho-History, Quanto-History, \&
		  History},
  isbn		= {978-0-226-03851-3},
  lccn		= {D13.B333},
  shorttitle	= {Clio and the Doctors},
  abstract	= {Clio and the Doctors (Midway Reprint Series) by Jacques
		  Barzun (1993)},
  publisher	= {{University of Chicago Press}},
  author	= {Barzun, Lacques},
  year		= {1974}
}

@Article{	  bearman_big_2015,
  title		= {Big Data and historical social science},
  volume	= {2},
  rights	= {© The Author(s) 2015. This article is distributed under
		  the terms of the Creative Commons
		  Attribution-{NonCommercial}-{NoDerivs} 3.0 License
		  (http://www.creativecommons.org/licenses/by-nc-nd/3.0/)
		  which permits non-commercial use, reproduction and
		  distribution of the work as published without adaptation or
		  alteration, without further permission provided the
		  original work is attributed as specified on the {SAGE} and
		  Open Access page
		  (https://us.sagepub.com/en-us/nam/open-access-at-sage).},
  issn		= {2053-9517},
  url		= {http://bds.sagepub.com/content/2/2/2053951715612497},
  doi		= {10.1177/2053951715612497},
  abstract	= {“Big Data” can revolutionize historical social science
		  if it arises from substantively important contexts and is
		  oriented towards answering substantively important
		  questions. Such data may be especially important for
		  answering previously largely intractable questions about
		  the timing and sequencing of events, and of event
		  boundaries. That said, “Big Data” makes no difference
		  for social scientists and historians whose accounts rest on
		  narrative sentences. Since such accounts are the norm, the
		  effects of Big Data on the practice of historical social
		  science may be more limited than one might wish.},
  pages		= {2053951715612497},
  number	= {2},
  journaltitle	= {Big Data \& Society},
  author	= {Bearman, Peter},
  urldate	= {2016-08-26},
  date		= {2015-12-01},
  langid	= {english},
  file		= {Full Text
		  PDF:/Users/lmullen/Zotero/storage/KDRXGDE3/Bearman - 2015 -
		  Big Data and historical social
		  science.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/BUXS7BEV/2053951715612497.html:text/html}
}

@InCollection{	  binder_alien_2016,
  title		= {Alien Reading: Text Mining, Language Standardization, and
		  the Humanities},
  url		= {http://dhdebates.gc.cuny.edu/debates/text/69},
  pages		= {201--17},
  booktitle	= {Debates in the Digital Humanities 2016},
  publisher	= {University of Minnesota Press},
  author	= {Binder, Jeffrey M.},
  editor	= {Gold, Matthew K. and Klein, Lauren F.},
  date		= {2016}
}

@Article{	  blei_probabilistic_2012,
  title		= {Probabilistic Topic Models},
  volume	= {55},
  issn		= {0001-0782},
  url		= {http://doi.acm.org/10.1145/2133806.2133826},
  doi		= {10.1145/2133806.2133826},
  abstract	= {Surveying a suite of algorithms that offer a solution to
		  managing large document archives.},
  pages		= {77--84},
  number	= {4},
  journaltitle	= {Commun. {ACM}},
  author	= {Blei, David M.},
  urldate	= {2016-08-26},
  date		= {2012-04},
  file		= {ACM Full Text
		  PDF:/Users/lmullen/Zotero/storage/4UQZUPKG/Blei - 2012 -
		  Probabilistic Topic Models.pdf:application/pdf}
}

@Article{	  blevins_space_2014,
  title		= {Space, {{Nation}}, and the {{Triumph}} of {{Region}}: {{A
		  View}} of the {{World}} from {{Houston}}},
  volume	= {101},
  issn		= {0021-8723,},
  shorttitle	= {Space, {{Nation}}, and the {{Triumph}} of {{Region}}},
  doi		= {10.1093/jahist/jau184},
  language	= {en},
  number	= {1},
  journal	= {Journal of American History},
  author	= {Blevins, Cameron},
  month		= jan,
  year		= {2014},
  pages		= {122--147}
}

@Article{	  blevins_space_2014,
  title		= {Space, Nation, and the Triumph of Region: A View of the
		  World from Houston},
  volume	= {101},
  issn		= {0021-8723,},
  url		= {http://jah.oxfordjournals.org/content/101/1/122},
  doi		= {10.1093/jahist/jau184},
  shorttitle	= {Space, Nation, and the Triumph of Region},
  pages		= {122--147},
  number	= {1},
  journaltitle	= {Journal of American History},
  shortjournal	= {Journal of American History},
  author	= {Blevins, Cameron},
  urldate	= {2016-01-20},
  date		= {2014-06-01},
  langid	= {english},
  file		= {Blevins - 2014 - Space, Nation, and the Triumph of Region
		  A View o.pdf:/Users/lmullen/Zotero/storage/24W8RPPN/Blevins
		  - 2014 - Space, Nation, and the Triumph of Region A View
		  o.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/K7RC9PBF/122.html:text/html}
}

@Article{	  block_doing_2006,
  title		= {Doing More with Digitization: An Introduction to Topic
		  Modeling of Early American Sources},
  volume	= {6},
  url		= {http://www.common-place-archives.org/vol-06/no-02/tales/},
  number	= {2},
  journaltitle	= {Common-Place},
  author	= {Block, Sharon},
  urldate	= {2016-08-22},
  date		= {2006-01},
  file		= {Common-place\: Tales from the
		  Vault:/Users/lmullen/Zotero/storage/U56UUEZ4/tales.html:text/html}
}

@Book{		  borgmanbigdatalittle2015,
  title		= {Big Data, Little Data, No Data: Scholarship in the
		  Networked World},
  isbn		= {978-0-262-32786-2},
  shorttitle	= {Big Data, Little Data, No Data},
  abstract	= {An examination of the uses of data within a changing
		  knowledge infrastructure, offering analysis and case
		  studies from the sciences, social sciences, and
		  humanities.},
  language	= {English},
  author	= {Borgman, Christine L},
  year		= {2015},
  note		= {OCLC: 900409008}
}

@Book{		  borgmanscholarshipdigitalage2007a,
  address	= {Cambridge, MA :},
  title		= {Scholarship in the {{Digital Age}}: {{Information}},
		  {{Infrastructure}}, and the {{Internet}}},
  isbn		= {9780262026192 (hardcover : alk. paper)},
  shorttitle	= {Scholarship in the {{Digital Age}}},
  publisher	= {{MIT Press}},
  author	= {Borgman, Christine L.},
  year		= {2007},
  file		= {/Users/jheppler/Zotero/storage/ENTKRQZA/7108580.html}
}

@Book{		  bryan_happy_2016,
  title		= {Happy Git and {GitHub} for the {useR}},
  url		= {http://happygitwithr.com/},
  abstract	= {Using Git and {GitHub} with R, Rstudio, and R Markdown},
  author	= {Bryan, Jenny},
  editora	= {{STAT 545 TAs}},
  editoratype	= {collaborator},
  urldate	= {2016-08-26},
  date		= {2016},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/JDVWPVZ2/happygitwithr.com.html:text/html}
}

@Article{	  burtonamericandigitalhistory2005,
  title		= {American {{Digital History}}},
  volume	= {23},
  lccn		= {0006},
  doi		= {10.1177/0894439304273317},
  abstract	= {U.S. History and Computing have had a long history of
		  partnership in teaching and research. There currently is a
		  deep divide among historians on the direction this
		  partnership will take in the future. Will the partnership
		  revolutionize theways in which history is taught and
		  researched or will it simply offer additional tools to
		  improve traditional practices? In either case, future
		  success depends on history scholars taking an active role
		  in the partnership. With active and involved historians,
		  great ideas such as digital libraries and online
		  educational materials can be developed into workable and
		  effective teaching and research tools. However, historians
		  must take the initiative. A pioneering group of historians
		  have laid the groundwork, nowthe profession must embrace
		  thiswork and move forward or it will be done for us by
		  those who are not historians.},
  number	= {2},
  journal	= {Social Science Computer Review},
  author	= {Burton, Orville Vernon},
  month		= may,
  year		= {2005},
  pages		= {206--220}
}

@Article{	  clubb_computers_1967,
  title		= {Computers and {{Historical Studies}}},
  volume	= {54},
  copyright	= {Copyright \textcopyright{} 1967 Organization of American
		  Historians},
  issn		= {0021-8723},
  doi		= {10.2307/2937409},
  number	= {3},
  journal	= {The Journal of American History},
  author	= {Clubb, Jerome M. and Allen, Howard},
  month		= dec,
  year		= {1967},
  pages		= {599--607}
}

@Article{	  cohenbabelknowledgedata2006,
  title		= {From {{Babel}} to {{Knowledge}}: {{Data Mining Large
		  Digital Collections}}},
  volume	= {12},
  lccn		= {0004},
  number	= {3},
  journal	= {D-Lib Magazine},
  author	= {Cohen, Daniel J.},
  month		= mar,
  year		= {2006},
  pages		= {6--19}
}

@Book{		  cohendigitalhistoryguide2005a,
  address	= {Philadelphia, PA},
  title		= {Digital {{History}}: {{A Guide}} to {{Gathering}},
		  {{Preserving}}, and {{Presenting}} the {{Past}} on the
		  {{Web}}},
  lccn		= {0060},
  publisher	= {{University of Pennsylvania Press}},
  author	= {Cohen, Daniel J. and Rosenzweig, Roy},
  year		= {2005}
}

@Article{	  cohenfuturepreserving2005,
  title		= {The {{Future}} of {{Preserving}} the {{Past}}},
  volume	= {2},
  lccn		= {0001},
  number	= {2},
  journal	= {CRM: The Journal of Heritage Stewardship},
  author	= {Cohen, Daniel J.},
  pages		= {6--19}
}

@Article{	  cohenhistoryseconddecade2004a,
  title		= {History and the Second Decade of the {{Web}}},
  volume	= {8},
  issn		= {1364-2529},
  lccn		= {0008},
  doi		= {10.1080/13642520410001683950},
  number	= {2},
  journal	= {Rethinking History},
  author	= {Cohen, Daniel J.},
  year		= {2004},
  pages		= {293}
}

@Book{		  cohenrosenzweig2005digitalhistory,
  author	= {Daniel Cohen and Roy Rosenzweig},
  title		= {Digital History: A Guide to Gathering, Preserving, and
		  Presenting the Past on the Web},
  shorttitle	= {Digital History},
  publisher	= {University of Pennsylvania Press},
  year		= 2005,
  address	= {Philadelphia}
}

@Article{	  cordell_reprinting_2015,
  title		= {Reprinting, Circulation, and the Network Author in
		  Antebellum Newspapers},
  volume	= {27},
  issn		= {0896-7148, 1468-4365},
  url		= {http://alh.oxfordjournals.org/content/27/3/417},
  doi		= {10.1093/alh/ajv028},
  pages		= {417--445},
  number	= {3},
  journaltitle	= {American Literary History},
  shortjournal	= {Am Lit Hist},
  author	= {Cordell, Ryan},
  urldate	= {2016-08-25},
  date		= {2015-09-01},
  langid	= {english},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/9CA7Q9CZ/417.html:text/html}
}

@Article{	  cranewhatyoumillion2006,
  title		= {What {{Do You Do}} with a {{Million Books}}?},
  volume	= {12},
  issn		= {1082-9873},
  doi		= {10.1045/march2006-crane},
  number	= {3},
  journal	= {D-Lib Magazine},
  author	= {Crane, Gregory},
  month		= mar,
  year		= {2006}
}

@Article{	  crymble_using_2015,
  title		= {Using Gazetteers to Extract Sets of Keywords from
		  Free-Flowing Texts},
  url		= {http://programminghistorian.org/lessons/extracting-keywords},
  journaltitle	= {Programming Historian},
  author	= {Crymble, Adam},
  urldate	= {2016-08-23},
  date		= {2015-12-01},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/5GQ4GH32/extracting-keywords.html:text/html}
}

@Book{		  dalgaard_introductory_2008,
  title		= {Introductory Statistics with R},
  isbn		= {978-0-387-79053-4 978-0-387-79054-1},
  url		= {http://link.springer.com/10.1007/978-0-387-79054-1},
  series	= {Statistics and Computing},
  publisher	= {Springer},
  author	= {Dalgaard, Peter},
  urldate	= {2016-08-23},
  date		= {2008}
}

@Article{	  drucker_humanities_2011,
  title		= {Humanities {{Approaches}} to {{Graphical Display}}},
  volume	= {5},
  number	= {001},
  journal	= {Digital Humanities Quarterly},
  author	= {Drucker, Johanna}
}

@Book{		  drucker_speclab_2009,
  address	= {Chicago},
  title		= {{{SpecLab}} : Digital Aesthetics and Projects in
		  Speculative Computing},
  isbn		= {978-0-226-16507-3},
  publisher	= {{University of Chicago Press}},
  author	= {Drucker, Johanna},
  year		= {2009}
}

@Article{	  earhart_digital_2016,
  title		= {Digital {{Humanities}} Futures: {{Conflict}}, Power, and
		  Public Knowledge},
  volume	= {0},
  issn		= {1918-3666},
  shorttitle	= {Digital {{Humanities}} Futures},
  number	= {0},
  journal	= {Digital Studies / Le champ num{\'e}rique},
  author	= {Earhart, Amy E.},
  month		= aug,
  year		= {2016}
}

@Article{	  finnane_prosecution_2016,
  title		= {The Prosecution Project: Understanding the Changing
		  Criminal Trial Through Digital Tools},
  volume	= {{FirstView}},
  issn		= {1939-9022},
  url		= {http://journals.cambridge.org/article_S0738248016000316},
  doi		= {10.1017/S0738248016000316},
  shorttitle	= {The Prosecution Project},
  abstract	= {The Prosecution Project is a large-scale digital project
		  that aims to provide a new way of exploring the context and
		  impact of changes in the criminal trial during the
		  nineteenth and twentieth centuries. It does so from an
		  elementary platform: the digitization of the court
		  calendars of criminal trials in the higher courts in the
		  six main Australian jurisdictions over time periods as long
		  as 130 years. The objective is to address questions of the
		  criminal justice process centered on prosecution, from
		  arrest, committal, and indictment, to verdict, sentence,
		  and beyond. In a field of historical research that is more
		  often characterized by the richness of discursive analysis,
		  the Prosecution Project's comparative data sets are
		  designed to offer a new understanding of quantitative
		  context over long periods of time. The challenge of
		  building the data platform is, however, considerable,
		  requiring significant planning, collaboration and
		  investment by a large number of researchers, working with
		  relevant archive repositories, and, in this case, assisted
		  by the engagement of an interested community lying outside
		  the regular academy. This article describes the background
		  to the project, its development as a collaborative digital
		  initiative, and its technical and organizational
		  requirements and possibilities, before we explore briefly
		  some of the research outcomes that this project makes
		  possible.},
  pages		= {1--19},
  journaltitle	= {Law and History Review},
  author	= {Finnane, Mark and Piper, Alana},
  urldate	= {2016-08-26},
  date		= {2016-08},
  file		= {Cambridge Journals
		  Snapshot:/Users/lmullen/Zotero/storage/849AJI43/displayAbstract.html:text/html}
}

@InCollection{	  flanders_data_2016,
  title		= {Data Modeling},
  pages		= {229--37},
  booktitle	= {A New Companion to the Digital Humanities},
  publisher	= {Wiley Blackwell},
  author	= {Flanders, Julia and Jannidis, Fotis},
  editor	= {Schreibman, Susan and Siemens, Ray and Unsworth, John},
  date		= {2016}
}

@Article{	  fogel_limits_1975,
  title		= {The {{Limits}} of {{Quantitative Methods}} in
		  {{History}}},
  volume	= {80},
  copyright	= {Copyright \textcopyright{} 1975 American Historical
		  Association},
  issn		= {0002-8762},
  doi		= {10.2307/1850498},
  number	= {2},
  journal	= {The American Historical Review},
  author	= {Fogel, Robert William},
  month		= apr,
  year		= {1975},
  pages		= {329--350}
}

@Book{		  fogel_time_1974,
  edition	= {Reissue},
  title		= {Time on the {{Cross}}: {{The Economics}} of {{American
		  Slavery}}},
  isbn		= {978-0-393-31218-8},
  shorttitle	= {Time on the {{Cross}}},
  publisher	= {{W. W. Norton \& Company}},
  author	= {Fogel, Robert William and Engerman, Stanley L.},
  year		= {1974}
}

@Article{	  forster_quantifying_1974,
  title		= {Quantifying {{History}}},
  volume	= {5},
  copyright	= {Copyright \textcopyright{} 1974 the Massachusetts
		  Institute of Technology and the editors of The Journal of
		  Interdisciplinary History},
  issn		= {0022-1953},
  doi		= {10.2307/202512},
  number	= {2},
  journal	= {The Journal of Interdisciplinary History},
  author	= {Forster, Robert},
  month		= oct,
  year		= {1974},
  pages		= {303--312},
  note		= {ArticleType: book-review / Full publication date: Autumn,
		  1974 / Copyright \textcopyright{} 1974 the Massachusetts
		  Institute of Technology and the editors of The Journal of
		  Interdisciplinary History}
}

@Article{	  fraas_mapping_2015,
  title		= {Mapping the State of the Union},
  issn		= {1072-7825},
  url		= {http://www.theatlantic.com/politics/archive/2015/01/mapping-the-state-of-the-union/384576/},
  abstract	= {An interactive graphic shows the 1,410 different spots on
		  the globe presidents have referenced in 224 speeches.},
  journaltitle	= {The Atlantic},
  author	= {Fraas, Mitch and Schmidt, Benjamin},
  urldate	= {2016-08-26},
  date		= {2015-01-18},
  file		= {The Atlantic
		  Snapshot:/Users/lmullen/Zotero/storage/HVE24V4B/384576.html:text/html}
}

@Book{		  friedman_history_1985,
  location	= {New York},
  edition	= {2nd},
  title		= {A history of American law},
  isbn		= {978-0-671-52807-2 978-0-671-81591-2},
  pagetotal	= {781},
  publisher	= {Simon \& Schuster},
  author	= {Friedman, Lawrence M.},
  date		= {1985},
  keywords	= {History, Law, United States}
}

@Article{	  furet_quantitative_1971,
  title		= {Quantitative {{History}}},
  volume	= {100},
  copyright	= {Copyright \textcopyright{} 1971 American Academy of Arts
		  \& Sciences},
  issn		= {0011-5266},
  doi		= {10.2307/20023996},
  number	= {1},
  journal	= {Daedalus},
  author	= {Furet, Fran{\c c}ois},
  month		= jan,
  year		= {1971},
  pages		= {151--167},
  note		= {ArticleType: research-article / Issue Title: Historical
		  Studies Today / Full publication date: Winter, 1971 /
		  Copyright \textcopyright{} 1971 American Academy of Arts \&
		  Sciences}
}

@Book{		  gitelmanalwaysalreadynew2006a,
  address	= {Cambridge, Mass},
  title		= {Always {{Already New}}: {{Media}}, {{History}} and the
		  {{Data}} of {{Culture}}},
  isbn		= {978-0-262-07271-7},
  lccn		= {P90 .G4776 2006},
  shorttitle	= {Always Already New},
  publisher	= {{MIT Press}},
  author	= {Gitelman, Lisa},
  year		= {2006},
  keywords	= {Communication and technology,History,Mass media,United
		  States}
}

@InCollection{	  gold_forum:_2016,
  title		= {Forum: Text Analysis at Scale},
  url		= {http://dhdebates.gc.cuny.edu/debates/text/93},
  pages		= {525--568},
  booktitle	= {Debates in the Digital Humanities 2016},
  publisher	= {University of Minnesota Press},
  author	= {Gold, Matthew K. and Klein, Lauren F. and Ramsay, Stephen
		  and Underwood, Ted and Clement, Tanya E. and Rhody, Lisa
		  Marie and {McMillan} Cottom, Tressie and Schmidt, Benjamin
		  M. and Swafford, Joanna and Liu, Alan},
  date		= {2016}
}

@Article{	  goldstone_quiet_2014,
  title		= {The Quiet Transformations of Literary Studies: What
		  Thirteen Thousand Scholars Could Tell Us},
  volume	= {45},
  issn		= {1080-661X},
  url		= {http://muse.jhu.edu/content/crossref/journals/new_literary_history/v045/45.3.goldstone.html},
  doi		= {10.1353/nlh.2014.0025},
  shorttitle	= {The Quiet Transformations of Literary Studies},
  pages		= {359--384},
  number	= {3},
  journaltitle	= {New Literary History},
  author	= {Goldstone, Andrew and Underwood, Ted},
  urldate	= {2016-08-26},
  date		= {2014},
  langid	= {english},
  file		= {Goldstone and Underwood - 2014 - The Quiet Transformations
		  of Literary Studies
		  Wha.pdf:/Users/lmullen/Zotero/storage/EEID44P5/Goldstone
		  and Underwood - 2014 - The Quiet Transformations of
		  Literary Studies Wha.pdf:application/pdf}
}

@Article{	  gordon_lost_2011,
  title		= {Lost in Space, or Confessions of an Accidental
		  Geographer},
  volume	= {5},
  issn		= {1753-8548},
  doi		= {10.3366/ijhac.2011.0018},
  abstract	= {This article reflects on the author's experience with
		  historical GIS during the research of his 2008 manuscript
		  Mapping Decline: St. Louis and the Fate of the American
		  City. It assesses, in turn, the utility of maps and their
		  role in historical research and writing; the investigatory
		  and explanatory potential of historical GIS; and some of
		  the limits and pitfalls of historical mapping.},
  number	= {1},
  journal	= {International Journal of Humanities and Arts Computing},
  author	= {Gordon, Colin},
  month		= mar,
  year		= {2011},
  keywords	= {Historiography,Sanborn maps,St. Louis,U.S.
		  Census,cartography,historical GIS,historical
		  mapping,historical method,modifiable area unit problem
		  (MAUP),urban history},
  pages		= {1--22},
  file		= {/Users/jasonheppler/Dropbox/research-papers/2011_Lost in
		  space, or confessions of an accidental geographer.pdf}
}

@Article{	  gouglas_before_2013,
  title		= {Before the {{Beginning}}: {{The Formation}} of
		  {{Humanities Computing}} as a {{Discipline}} in
		  {{Canada}}},
  volume	= {3},
  issn		= {1918-3666},
  shorttitle	= {Before the {{Beginning}}},
  number	= {1},
  journal	= {Digital Studies / Le champ num{\'e}rique},
  author	= {Gouglas, Sean and Rockwell, Geoffrey and Smith, Victoria
		  and Hoosein, Sophia and Quamen, Harvey},
  month		= feb,
  year		= {2013}
}

@Book{		  graham_exploring_2015,
  title		= {Exploring Big Historical Data: The Historian's
		  Macroscope},
  isbn		= {978-1-78326-637-1},
  shorttitle	= {Exploring Big Historical Data},
  abstract	= {The Digital Humanities have arrived at a moment when
		  digital Big Data is becoming more readily available,
		  opening exciting new avenues of inquiry but also new
		  challenges. This pioneering book describes and demonstrates
		  the ways these data can be explored to construct cultural
		  heritage knowledge, for research and in teaching and
		  learning. It helps humanities scholars to grasp Big Data in
		  order to do their work, whether that means understanding
		  the underlying algorithms at work in search engines, or
		  designing and using their own tools to process large
		  amounts of information. Demonstrating what digital tools
		  have to offer and also what 'digital' does to how we
		  understand the past, the authors introduce the many
		  different tools and developing approaches in Big Data for
		  historical and humanistic scholarship, show how to use
		  them, what to be wary of, and discuss the kinds of
		  questions and new perspectives this new macroscopic
		  perspective opens up. Authored 'live' online with ongoing
		  feedback from the wider digital history community,
		  Exploring Big Historical Data breaks new ground and sets
		  the direction for the conversation into the future. It
		  represents the current state-of-the-art thinking in the
		  field and exemplifies the way that digital work can enhance
		  public engagement in the humanities. Exploring Big
		  Historical Data should be the go-to resource for
		  undergraduate and graduate students confronted by a vast
		  corpus of data, and researchers encountering these methods
		  for the first time. It will also offer a helping hand to
		  the interested individual seeking to make sense of
		  genealogical data or digitized newspapers, and even the
		  local historical society who are trying to see the value in
		  digitizing their holdings. Readership: Researchers,
		  graduate and undergraduate students in the field of Digital
		  Humanities, and people looking to digitize historical
		  archives.},
  pagetotal	= {305},
  publisher	= {Imperial College Press},
  author	= {Graham, Shawn and Milligan, Ian and Weingart, Scott},
  date		= {2015-11-16}
}

@Article{	  greasley_clio_2010,
  title		= {Clio and the {{Economist}}: {{Making Historians Count}}},
  volume	= {24},
  copyright	= {\textcopyright{} 2010 Blackwell Publishing Ltd},
  issn		= {1467-6419},
  shorttitle	= {{{CLIO AND THE ECONOMIST}}},
  doi		= {10.1111/j.1467-6419.2010.00649.x},
  abstract	= {Abstract Cliometrics reconnected economic history and
		  economics in the 1960s. The deeper foundations of
		  cliometrics research lie in the longer standing traditions
		  of quantitative history and the contemporaneous growth of
		  the social sciences and computing. Early cliometrics
		  research reinterpreted economic history through the lens of
		  neo-classical economics. Over the past half century
		  cliometrics has matured and now utilizes a broad array of
		  theoretical perspectives and statistical methods to help
		  understand the past. The papers introduced here illustrate
		  the achievements of several key areas of cliometrics
		  research and show how new theoretical perspectives,
		  innovative data construction and sophisticated econometric
		  methods are the hallmarks of the discipline.},
  language	= {en},
  number	= {5},
  journal	= {Journal of Economic Surveys},
  author	= {Greasley, David and Oxley, Les},
  month		= dec,
  year		= {2010},
  keywords	= {Anthropometrics,Cliometrics,Human development
		  index,Immigration,Social savings,Social welfare
		  programmes,Time series},
  pages		= {755--774}
}

@Article{	  greif_cliometrics_1997,
  title		= {Cliometrics {{After}} 40 {{Years}}},
  volume	= {87},
  issn		= {0002-8282},
  number	= {2},
  journal	= {The American Economic Review},
  author	= {Greif, Avner},
  month		= may,
  year		= {1997},
  pages		= {400--403},
  note		= {ArticleType: research-article / Issue Title: Papers and
		  Proceedings of the Hundred and Fourth Annual Meeting of the
		  American Economic Association / Full publication date: May,
		  1997 / Copyright \textcopyright{} 1997 American Economic
		  Association}
}

@Article{	  hitchcock_old_2016,
  title		= {The Old Bailey Proceedings, 1674–1913: Text Mining for
		  Evidence of Court Behavior},
  volume	= {34},
  issn		= {1939-9022},
  url		= {http://journals.cambridge.org/article_S0738248016000304},
  doi		= {10.1017/S0738248016000304},
  shorttitle	= {The Old Bailey Proceedings, 1674–1913},
  abstract	= {The shortest trial report in the Old Bailey Proceedings is
		  precisely eight words in length. In February, 1685:
		  Elizabeth Draper, Indicted for Felony, was found Guilty.},
  pages		= {1--27},
  number	= {4},
  journaltitle	= {Law and History Review},
  author	= {Hitchcock, Tim and Turkel, William J.},
  urldate	= {2016-08-26},
  date		= {2016-08}
}

@Book{		  hoeflich_legal_2010,
  location	= {New York},
  title		= {Legal publishing in antebellum America},
  isbn		= {978-0-521-19206-4},
  abstract	= {Legal Publishing in Antebellum America presents a history
		  of the law book publishing and distribution industry in the
		  United States. Part business history, part legal history,
		  part history of information diffusion, M. H. Hoeflich shows
		  how various developments in printing and bookbinding, the
		  introduction of railroads, and the expansion of mail
		  service contributed to the growth of the industry from an
		  essentially local industry to a national industry.
		  Furthermore, the book ties the spread of a particular
		  approach to law, that is, the scientific approach,
		  championed by Northeastern American jurists to the growth
		  of law publishing and law book selling and shows that the
		  two were critically intertwined --Provided by publisher},
  pagetotal	= {190},
  publisher	= {Cambridge University Press},
  author	= {Hoeflich, Michael H.},
  date		= {2010},
  note		= {{OCLC}: ocn489001671},
  keywords	= {18th century, 19th century, Legal literature, Publishing
		  History, United States}
}

@Book{		  james_introduction_2013,
  title		= {An Introduction to Statistical Learning with Applications
		  in R},
  isbn		= {978-1-4614-7138-7},
  publisher	= {Springer},
  author	= {James, Gareth and Witten, Daniela and Hastie, Trevor and
		  Tibshirani, Robert},
  date		= {2013},
  keywords	= {{GNU}-S (Computer program language), Mathematical
		  statistics., Mathematics Statistical methods, R (Computer
		  program language), Statistical inference, Statistics,
		  Mathematical},
  file		= {James - 2013 - An Introduction to Statistical Learning
		  with Appli.pdf:/Users/lmullen/Zotero/storage/NFBDH44C/James
		  - 2013 - An Introduction to Statistical Learning with
		  Appli.pdf:application/pdf}
}

@Article{	  jessopvisualizationspatialdata2004,
  title		= {The {{Visualization}} of {{Spatial Data}} in the
		  {{Humanities}}},
  volume	= {19},
  abstract	= {The visualization and analysis of spatial data can shed
		  new light on the nature and meaning of data throughout the
		  Humanities. However such work is often avoided because it
		  is seen as requiring expensive new hardware and software
		  resources or involving a substantial expenditure of time
		  and effort overcoming a steep learning curve before
		  worthwhile results can be obtained. The Centre for
		  Computing in the Humanities at King's College London
		  collaborates with researchers in a variety of humanities
		  disciplines on a range of projects that often involve a
		  component of spatial data. This has given the Centre an
		  oppor- tunity to explore methods of visualizing, analysing
		  and displaying spatial data in a range of humanities
		  disciplines. This paper discusses some of the intellectual,
		  research and practical issues affecting the use of spatial
		  data in Humanities Computing projects. It is illustrated by
		  examples from a number of projects at King's College.
		  Although it is grounded on specific examples to support the
		  points being made the main aim is to draw out a series of
		  general themes which affect the use of spatial data by
		  researchers throughout the Humanities and increase
		  awareness of what can be achieved with minimal resources
		  and a little creative thought.},
  number	= {3},
  journal	= {Literary and Linguistic Computing},
  author	= {Jessop, Martyn},
  year		= {2004},
  file		= {/Users/jasonheppler/Dropbox/research-papers/Jessop_2004_The
		  Visualization of Spatial Data in the
		  Humanities.pdf;/Users/jheppler/Zotero/storage/IW4WVUZV/Jessop
		  - 2004 - The Visualization of Spatial Data in the
		  Humanitie.pdf}
}

@Book{		  jockers_macroanalysis:_2013,
  title		= {Macroanalysis: {{Digital Methods}} and {{Literary
		  History}}},
  publisher	= {{UIUC Press}},
  author	= {Jockers, Matthew},
  year		= {2013}
}

@Book{		  jockers_macroanalysis:_2013,
  title		= {Macroanalysis: Digital Methods and Literary History},
  isbn		= {978-0-252-03752-8 978-0-252-07907-8 978-0-252-09476-7},
  shorttitle	= {Macroanalysis},
  pagetotal	= {192},
  publisher	= {University of Illinois Press},
  author	= {Jockers, Matthew L.},
  date		= {2013},
  keywords	= {{LITERATURE}, Research Data processing, Research
		  Methodology}
}

@InCollection{	  jockers_text-mining_2016,
  title		= {Text-Mining the Humanities},
  pages		= {291--306},
  booktitle	= {A New Companion to the Digital Humanities},
  publisher	= {Wiley Blackwell},
  author	= {Jockers, Matthew L. and Underwood, Ted},
  editor	= {Schreibman, Susan and Siemens, Ray and Unsworth, John},
  date		= {2016}
}

@Book{		  jockers_text_2014,
  title		= {Text Analysis with R for Students of Literature},
  isbn		= {978-3-319-03163-7 978-3-319-03164-4},
  url		= {http://link.springer.com/10.1007/978-3-319-03164-4},
  shorttitle	= {Text Analysis},
  publisher	= {Springer},
  author	= {Jockers, Matthew L.},
  urldate	= {2016-08-23},
  date		= {2014},
  file		= {Jockers - 2014 - Text Analysis with R for Students of
		  Literature.pdf:/Users/lmullen/Zotero/storage/95KEAJ9B/Jockers
		  - 2014 - Text Analysis with R for Students of
		  Literature.pdf:application/pdf}
}

@Book{		  jurafsky_speech_2008,
  edition	= {2nd},
  title		= {Speech and Language Processing, 2nd Edition},
  isbn		= {978-0-13-187321-6},
  abstract	= {For undergraduate or advanced undergraduate courses in
		  Classical Natural Language Processing, Statistical Natural
		  Language Processing, Speech Recognition, Computational
		  Linguistics, and Human Language Processing.   An explosion
		  of Web-based language techniques, merging of distinct
		  fields, availability of phone-based dialogue systems, and
		  much more make this an exciting time in speech and language
		  processing. The first of its kind to thoroughly cover
		  language technology – at all levels and with all modern
		  technologies – this text takes an empirical approach to
		  the subject, based on applying statistical and other
		  machine-learning algorithms to large corporations. The
		  authors cover areas that traditionally are taught in
		  different courses, to describe a unified vision of speech
		  and language processing. Emphasis is on practical
		  applications and scientific evaluation. An accompanying
		  Website contains teaching materials for instructors, with
		  pointers to language processing resources on the Web. The
		  Second Edition offers a significant amount of new and
		  extended material.   Supplements:   Click on the
		  "Resources" tab to View Downloadable Files: Solutions Power
		  Point Lecture Slides - Chapters 1-5, 8-10, 12-13 and 24
		  Now Available! For additional resourcse visit the author
		  website:
		  http://www.cs.colorado.edu/{\textasciitilde}martin/slp.html},
  pagetotal	= {1024},
  publisher	= {Prentice Hall},
  author	= {Jurafsky, Daniel and Martin, James H.},
  date		= {2008-05-16}
}

@Article{	  kirschenbaumwhatdigitalhumanities2010,
  title		= {What Is {{Digital Humanities}} and {{What}}'s It {{Doing}}
		  in {{English Departments}}?},
  volume	= {150},
  journal	= {ADE Bulletin},
  author	= {Kirschenbaum, Matthew G.},
  year		= {2010},
  pages		= {55--61}
}

@Article{	  knox_understanding_2013,
  title		= {Understanding Regular Expressions},
  url		= {http://programminghistorian.org/lessons/understanding-regular-expressions},
  journaltitle	= {Programming Historian},
  author	= {Knox, Doug},
  urldate	= {2016-08-23},
  date		= {2013-06-22},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/TSE4F8TI/understanding-regular-expressions.html:text/html}
}

@Book{		  kuhn_applied_2013,
  title		= {Applied Predictive Modeling},
  isbn		= {978-1-4614-6849-3},
  abstract	= {Includes bibliographical references and index.},
  publisher	= {Springer},
  author	= {Kuhn, Max and Johnson, Kjell},
  date		= {2013},
  keywords	= {Forecasting theory, Mathematical models., Mathematical
		  statistics., Mathematics Statistical methods, Models,
		  Mathematical, Prediction theory., Statistical inference,
		  Statistics, Mathematical}
}

@InProceedings{	  kusner_word_2015,
  title		= {From word embeddings to document distances},
  url		= {http://www.jmlr.org/proceedings/papers/v37/kusnerb15.pdf},
  pages		= {957--966},
  booktitle	= {Proceedings of the 32nd International Conference on
		  Machine Learning ({ICML} 2015)},
  author	= {Kusner, Matt J. and Sun, Yu and Kolkin, Nicholas I. and
		  Weinberger, Kilian Q.},
  urldate	= {2016-08-26},
  date		= {2015},
  file		= {Kusner et al. - 2015 - From word embeddings to document
		  distances.pdf:/Users/lmullen/Zotero/storage/UAHMI9WC/Kusner
		  et al. - 2015 - From word embeddings to document
		  distances.pdf:application/pdf}
}

@Book{		  leskovec_mining_2014,
  edition	= {2nd},
  title		= {Mining of Massive Datasets},
  url		= {http://www.mmds.org/},
  publisher	= {Cambridge University Press},
  author	= {Leskovec, Jure and Rajaraman, Anand and Ullman, Jeff},
  date		= {2014}
}

@Article{	  lipp_kinship_2005,
  title		= {Kinship {{Networks}}, {{Local Government}}, and
		  {{Elections}} in a {{Town}} in {{Southwest Germany}},
		  1800-1850},
  volume	= {30},
  issn		= {0363-1990, 1552-5473},
  doi		= {10.1177/0363199005278726},
  abstract	= {This article is based on the thesis that kinship
		  structures were an important element of communal politics
		  and were thus inscribed into the political system of even
		  early constitutionalism. The investigation presented covers
		  an important change in the political culture from the
		  Ancien R{\'e}gime to the modern constitutional state in
		  southwest Germany, and it raises the question of whether
		  election processes affected traditional structures of
		  representation based on kinship relationships and the
		  ascription of political competence to an elite of notables.
		  The analysis of kinship networks within the city council
		  and city deputation, however, comes to the opposite
		  conclusion\textemdash{}that kinship networks survive even
		  in a system where each year people were newly elected. The
		  analysis of voters' alignments along kinship lines also
		  demonstrates the power and persistence of kinship
		  structures in the early nineteenth century and reflects the
		  differences between kinship mobilization within
		  agriculturally bound and urban artisan groups.},
  language	= {en},
  number	= {4},
  journal	= {Journal of Family History},
  author	= {Lipp, Carola},
  month		= jan,
  year		= {2005},
  keywords	= {Germany,Kinship,Political culture,Social
		  Networks,constitutionalism,early
		  constitutionalism,elite,local elite,social network
		  analysis},
  pages		= {347--365}
}

@Article{	  liu_state_2012,
  title		= {The State of the Digital Humanities {{A}} Report and a
		  Critique},
  volume	= {11},
  issn		= {1474-0222, 1741-265X},
  doi		= {10.1177/1474022211427364},
  abstract	= {The scholarly field of the digital humanities has recently
		  expanded and integrated its fundamental concepts,
		  historical coverage, relationship to social experience,
		  scale of projects, and range of interpretive approaches.
		  All this brings the overall field (including the related
		  area of new media studies) to a tipping point where it has
		  the potential not just to facilitate the work of the
		  humanities but to represent the state of the humanities at
		  large in its changing relation to higher education in the
		  postindustrial state. Are the digital humanities up to this
		  larger task?},
  language	= {en},
  number	= {1-2},
  journal	= {Arts and Humanities in Higher Education},
  author	= {Liu, Alan},
  month		= feb,
  year		= {2012},
  keywords	= {Humanities,digital humanities,higher education,new media
		  studies},
  pages		= {8--41}
}

@Article{	  lorang_developing_2015,
  title		= {Developing an Image-Based Classifier for Detecting Poetic
		  Content in Historic Newspaper Collections},
  volume	= {21},
  issn		= {1082-9873},
  url		= {http://www.dlib.org/dlib/july15/lorang/07lorang.html},
  doi		= {10.1045/july2015-lorang},
  number	= {7},
  journaltitle	= {D-Lib Magazine},
  author	= {Lorang, Elizabeth and Soh, Leen-Kiat and Datla, Maanas
		  Varma and Kulwicki, Spencer},
  urldate	= {2016-08-22},
  date		= {2015-07},
  langid	= {english}
}

@Book{		  manovichlanguagenewmedia2002a,
  title		= {The {{Language}} of {{New Media}}},
  isbn		= {0-262-63255-1 978-0-262-63255-3},
  lccn		= {0001},
  publisher	= {{MIT Press}},
  author	= {Manovich, Lev},
  month		= mar,
  year		= {2002}
}

@Article{	  mccarty_getting_2014,
  title		= {Getting There from Here. {{Remembering}} the Future of
		  Digital Humanities {{Roberto Busa Award}} Lecture 2013},
  volume	= {29},
  issn		= {0268-1145, 1477-4615},
  doi		= {10.1093/llc/fqu022},
  abstract	= {In this slightly modified version of my 2013 Roberto Busa
		  Prize lecture, I look from the first four decades of
		  digital humanities through its present toward a possible
		  future. I find a means to construct this future by paying
		  close attention to the enemy we need in order to grow: the
		  fear that closed down the horizons of imaginative
		  exploration during the years of the Cold War and that
		  re-presents itself now clothed in numerous
		  techno-scientific challenges to the human.},
  language	= {en},
  number	= {3},
  journal	= {Literary and Linguistic Computing},
  author	= {McCarty, Willard},
  month		= jan,
  year		= {2014},
  pages		= {283--306}
}

@Article{	  mccloskey_achievements_1978,
  title		= {The {{Achievements}} of the {{Cliometric School}}},
  volume	= {38},
  issn		= {0022-0507},
  abstract	= {The twentieth (or so) birthday of the "new" economic
		  history is perhaps excuse enough for celebration.
		  Cliometrics is not counting, but applied theory--especially
		  the theory of price. The three accomplishments follow:
		  using theory to rethink bad economics about history; using
		  theory to remeasurement to reinterpret history, especially,
		  thus far, American. The cutting edge of cliometrices
		  nowadays is in fact other histories, from medieval Europe
		  to British India. Much blood has been spilt in the cutting,
		  but cliometrices entries its third decade healthy as
		  history and healthy as economics.},
  number	= {1},
  journal	= {The Journal of Economic History},
  author	= {McCloskey, Donald N.},
  month		= mar,
  year		= {1978},
  pages		= {13--28},
  note		= {ArticleType: research-article / Issue Title: The Tasks of
		  Economic History / Full publication date: Mar., 1978 /
		  Copyright \textcopyright{} 1978 Economic History
		  Association}
}

@Article{	  michel_quantitative_2011,
  title		= {Quantitative {{Analysis}} of {{Culture Using Millions}} of
		  {{Digitized Books}}},
  volume	= {331},
  doi		= {10.1126/science.1199644},
  abstract	= {We constructed a corpus of digitized texts containing
		  about 4\% of all books ever printed. Analysis of this
		  corpus enables us to investigate cultural trends
		  quantitatively. We survey the vast terrain of
		  `culturomics,' focusing on linguistic and cultural
		  phenomena that were reflected in the English language
		  between 1800 and 2000. We show how this approach can
		  provide insights about fields as diverse as lexicography,
		  the evolution of grammar, collective memory, the adoption
		  of technology, the pursuit of fame, censorship, and
		  historical epidemiology. Culturomics extends the boundaries
		  of rigorous quantitative inquiry to a wide array of new
		  phenomena spanning the social sciences and the humanities.},
  number	= {6014},
  journal	= {Science},
  author	= {Michel, Jean-Baptiste and Shen, Yuan Kui and Aiden, Aviva
		  Presser and Veres, Adrian and Gray, Matthew K. and The
		  Google Books Team and Pickett, Joseph P. and Hoiberg, Dale
		  and Clancy, Dan and Norvig, Peter and Orwant, Jon and
		  Pinker, Steven and Nowak, Martin A. and Aiden, Erez
		  Lieberman},
  month		= jan,
  year		= {2011},
  pages		= {176 --182}
}

@Article{	  michel_quantitative_2011,
  title		= {Quantitative Analysis of Culture Using Millions of
		  Digitized Books},
  volume	= {331},
  rights	= {Copyright © 2011, American Association for the
		  Advancement of Science},
  issn		= {0036-8075, 1095-9203},
  url		= {http://science.sciencemag.org/content/331/6014/176},
  doi		= {10.1126/science.1199644},
  abstract	= {We constructed a corpus of digitized texts containing
		  about 4\% of all books ever printed. Analysis of this
		  corpus enables us to investigate cultural trends
		  quantitatively. We survey the vast terrain of
		  ‘culturomics,’ focusing on linguistic and cultural
		  phenomena that were reflected in the English language
		  between 1800 and 2000. We show how this approach can
		  provide insights about fields as diverse as lexicography,
		  the evolution of grammar, collective memory, the adoption
		  of technology, the pursuit of fame, censorship, and
		  historical epidemiology. Culturomics extends the boundaries
		  of rigorous quantitative inquiry to a wide array of new
		  phenomena spanning the social sciences and the humanities.
		  Linguistic and cultural changes are revealed through the
		  analyses of words appearing in books. Linguistic and
		  cultural changes are revealed through the analyses of words
		  appearing in books.},
  pages		= {176--182},
  number	= {6014},
  journaltitle	= {Science},
  author	= {Michel, Jean-Baptiste and Shen, Yuan Kui and Aiden, Aviva
		  Presser and Veres, Adrian and Gray, Matthew K. and Team,
		  The Google Books and Pickett, Joseph P. and Hoiberg, Dale
		  and Clancy, Dan and Norvig, Peter and Orwant, Jon and
		  Pinker, Steven and Nowak, Martin A. and Aiden, Erez
		  Lieberman},
  urldate	= {2016-08-26},
  date		= {2011-01-14},
  langid	= {english},
  pmid		= {21163965},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/EQPZK89M/176.html:text/html}
}

@Article{	  mikolov_distributed_2013,
  title		= {Distributed representations of words and phrases and their
		  compositionality},
  journaltitle	= {Advances in neural information processing systems},
  author	= {Mikolov, T. and Dean, J.},
  date		= {2013},
  file		= {5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf:/Users/lmullen/Zotero/storage/7RKIWE8K/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf:application/pdf}
}

@Article{	  milligan_automated_2012,
  title		= {Automated Downloading with Wget},
  url		= {http://programminghistorian.org/lessons/automated-downloading-with-wget},
  journaltitle	= {Programming Historian},
  author	= {Milligan, Ian},
  urldate	= {2016-08-23},
  date		= {2012-06-27},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/K8CXN9P2/automated-downloading-with-wget.html:text/html}
}

@Article{	  mimno_computational_2012,
  title		= {Computational Historiography: {{Data}} Mining in a Century
		  of Classics Journals},
  volume	= {5},
  issn		= {1556-4673},
  shorttitle	= {Computational Historiography},
  doi		= {10.1145/2160165.2160168},
  abstract	= {More than a century of modern Classical scholarship has
		  created a vast archive of journal publications that is now
		  becoming available online. Most of this work currently
		  receives little, if any, attention. The collection is too
		  large to be read by any single person and mostly not of
		  sufficient interest to warrant traditional close reading.
		  This article presents computational methods for identifying
		  patterns and testing hypotheses about Classics as a field.
		  Such tools can help organize large collections, introduce
		  younger scholars to the history of the field, and act as a
		  ``survey,'' identifying anomalies that can be explored
		  using more traditional methods.},
  number	= {1},
  journal	= {J. Comput. Cult. Herit.},
  author	= {Mimno, David},
  month		= apr,
  year		= {2012},
  pages		= {3:1--3:19}
}

@Book{		  moretti_distant_2013,
  title		= {Distant reading},
  isbn		= {978-1-78168-084-1 978-1-78168-112-1},
  pagetotal	= {244},
  publisher	= {Verso},
  author	= {Moretti, Franco},
  date		= {2013},
  keywords	= {Criticism, History and criticism Theory, etc,
		  {LITERATURE}}
}

@Book{		  moretti_graphs_2005,
  title		= {Graphs, maps, trees: abstract models for a literary
		  history},
  isbn		= {978-1-84467-026-0},
  shorttitle	= {Graphs, maps, trees},
  pagetotal	= {119},
  publisher	= {Verso},
  author	= {Moretti, Franco},
  date		= {2005},
  keywords	= {Chronology, Criticism, Fiction, History and criticism,
		  {LITERATURE}, Philosophy}
}

@Book{		  morettigraphsmapstrees2005,
  address	= {London ; New York},
  title		= {Graphs, {{Maps}}, {{Trees}}: {{Abstract Models}} for a
		  {{Literary History}}},
  isbn		= {1-84467-026-0},
  lccn		= {PN3331 .M67 2005},
  shorttitle	= {Graphs, Maps, Trees},
  language	= {English},
  publisher	= {{Verso}},
  author	= {Moretti, Franco},
  year		= {2005},
  keywords	= {Criticism.,Fiction History and criticism.,Literature
		  Chronology.,Literature Miscellanea.,Literature
		  Philosophy.}
}

@Book{		  murrayhamletholodeckfuture1998a,
  address	= {Cambridge, MA},
  title		= {Hamlet on the {{Holodeck}}: {{The Future}} of
		  {{Narrative}} in {{Cyberspace}}},
  isbn		= {0-262-63187-3},
  lccn		= {0006},
  shorttitle	= {Hamlet on the {{Holodeck}}},
  publisher	= {{The MIT Press}},
  author	= {Murray, Janet H.},
  year		= {1998}
}

@Article{	  newman_probabilistic_2006,
  title		= {Probabilistic topic decomposition of an eighteenth-century
		  American newspaper},
  volume	= {57},
  url		= {http://onlinelibrary.wiley.com/doi/10.1002/asi.20342/full},
  pages		= {753--767},
  number	= {6},
  journaltitle	= {Journal of the American Society for Information Science
		  and Technology},
  author	= {Newman, David J. and Block, Sharon},
  urldate	= {2016-08-22},
  date		= {2006},
  file		= {Newman and Block - 2006 - Probabilistic topic
		  decomposition of an
		  eighteenth.pdf:/Users/lmullen/Zotero/storage/8DZK5333/Newman
		  and Block - 2006 - Probabilistic topic decomposition of an
		  eighteenth.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/4FQXM7ED/full.html:text/html}
}

@Article{	  oconnor_computational_2011,
  title		= {Computational text analysis for social science: Model
		  assumptions and complexity},
  url		= {http://repository.cmu.edu/lti/212/},
  shorttitle	= {Computational text analysis for social science},
  author	= {O'Connor, Brendan and Bamman, David and Smith, Noah A.},
  urldate	= {2016-08-26},
  date		= {2011},
  file		= {OConnor.pdf:/Users/lmullen/Zotero/storage/P5TDGWSA/OConnor.pdf:application/pdf;[PDF]
		  cmu.edu:/Users/lmullen/Zotero/storage/JH4QPZVZ/O'Connor et
		  al. - 2011 - Computational text analysis for social science
		  Mo.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/MAEBWU44/212.html:text/html}
}

@Article{	  omalleybravenewworld1997b,
  title		= {Brave {{New World}} or {{Blind Alley}}? {{American
		  History}} on the {{World Wide Web}}},
  volume	= {84},
  issn		= {00218723},
  lccn		= {0020},
  shorttitle	= {Brave {{New World}} or {{Blind Alley}}?},
  doi		= {10.2307/2952737},
  number	= {1},
  journal	= {The Journal of American History},
  author	= {O'Malley, Michael and Rosenzweig, Roy},
  month		= jun,
  year		= {1997},
  pages		= {132--155},
  note		= {ArticleType: primary\_article / Full publication date:
		  Jun., 1997 / Copyright \textcopyright{} 1997 Organization
		  of American Historians}
}

@Article{	  padgett_robust_1993,
  title		= {Robust {{Action}} and the {{Rise}} of the {{Medici}},
		  1400-1434},
  volume	= {98},
  issn		= {0002-9602},
  abstract	= {We analyze the centralization of political parties and
		  elite networks that underlay the birth of the Renaissance
		  state in Florence. Class revolt and fisical crisis were the
		  ultimate causes of elite consolidation, but Medicean
		  political control was produced by means of network
		  disjunctures within the elite, which the Medici alone
		  spanned. Cosimo de' Medici's multivocal identity as sphinx
		  harnessed the power available in these network holes and
		  resolved the contradiction between judge and boss inherent
		  in all organizations. Methodologically, we argue that to
		  understand state formation one must penetrate beneath the
		  veneer of formal institutions, groups, and goals down to
		  the relational substrata of peoples' actual lives.
		  Ambiguity and heterogeneity, not planning and self-
		  interest, are the raw materials of which powerful states
		  and persons are constructed.},
  number	= {6},
  journal	= {American Journal of Sociology},
  author	= {Padgett, John F. and Ansell, Christopher K.},
  month		= may,
  year		= {1993},
  pages		= {1259--1319},
  note		= {ArticleType: research-article / Full publication date:
		  May, 1993 / Copyright \textcopyright{} 1993 The University
		  of Chicago Press}
}

@InProceedings{	  pennington_glove:_2014,
  title		= {Glove: Global Vectors for Word Representation.},
  volume	= {14},
  url		= {http://llcao.net/cu-deeplearning15/presentation/nn-pres.pdf},
  shorttitle	= {Glove},
  pages		= {1532--43},
  booktitle	= {{EMNLP}},
  author	= {Pennington, Jeffrey and Socher, Richard and Manning,
		  Christopher D.},
  urldate	= {2016-08-26},
  date		= {2014},
  file		= {glove.pdf:/Users/lmullen/Zotero/storage/6K8MZZMX/glove.pdf:application/pdf;[PDF]
		  llcao.net:/Users/lmullen/Zotero/storage/3SI52QVV/Pennington
		  et al. - 2014 - Glove Global Vectors for Word
		  Representation..pdf:application/pdf}
}

@Article{	  price_recent_1969,
  title		= {Recent {{Quantitative Work}} in {{History}}: {{A Survey}}
		  of the {{Main Trends}}},
  volume	= {9},
  copyright	= {Copyright \textcopyright{} 1969 Wesleyan University},
  issn		= {0018-2656},
  shorttitle	= {Recent {{Quantitative Work}} in {{History}}},
  doi		= {10.2307/2504167},
  journal	= {History and Theory},
  author	= {Price, Jacob M.},
  month		= jan,
  year		= {1969},
  pages		= {1--13}
}

@Article{	  putnam_transnational_2016,
  title		= {The {{Transnational}} and the {{Text}}-{{Searchable}}:
		  {{Digitized Sources}} and the {{Shadows They Cast}}},
  volume	= {121},
  issn		= {0002-8762, 1937-5239},
  shorttitle	= {The {{Transnational}} and the {{Text}}-{{Searchable}}},
  doi		= {10.1093/ahr/121.2.377},
  abstract	= {This essay explores the consequences for historians'
		  research of the twinned transnational and digitized turns.
		  The accelerating digitization of primary and secondary
		  sources and the rise of full-text web-based search to
		  access information within them has transformed historians'
		  research practice, radically diminishing the role of
		  place-specific prior expertise as a prerequisite to
		  discovery. Indeed, we can now find information without
		  knowing where to look. This has incited remarkably little
		  reflection among mainstream historians, but the
		  consequences are profound. What has become newly possible?
		  How do the new digital affordances relate to the current
		  boom in transnational topics and approaches? How do the
		  reach, speed, and granularity of digitized search impact
		  our ability to reconstruct the supranational past? This
		  essay heralds the novel forms of knowledge-generation made
		  possible by technological transformations. It also attempts
		  an accounting of all the ancillary learning that
		  international research in an analog world once required.
		  What kinds of knowledge and insight did place-based
		  research across borders instill? What are the intellectual
		  and political consequences of leaving that behind?},
  language	= {en},
  number	= {2},
  journal	= {The American Historical Review},
  author	= {Putnam, Lara},
  month		= jan,
  year		= {2016},
  keywords	= {digital search,digitization,historical
		  methods,transnational history},
  pages		= {377--402}
}

@Article{	  raben_humanities_1991,
  title		= {Humanities Computing 25 Years Later},
  volume	= {25},
  issn		= {0010-4817, 1572-8412},
  doi		= {10.1007/BF00141184},
  abstract	= {This paper attempts to provide an overview of the
		  development of humanities computing during the past
		  twenty-five years. Mention is made of the major
		  applications of the computer to humanities disciplines, and
		  of the most important and representative projects across
		  the world.},
  language	= {en},
  number	= {6},
  journal	= {Computers and the Humanities},
  author	= {Raben, Joseph},
  year		= {1991},
  pages		= {341--350}
}

@Book{		  ramsay_reading_2011,
  title		= {Reading Machines: Toward an Algorithmic Criticism},
  isbn		= {0252078209 (pbk.)},
  publisher	= {University of Illinois Press},
  author	= {Ramsay, Stephen},
  date		= {2011},
  keywords	= {\#read}
}

@Article{	  ramsay_reconceiving_2003,
  title		= {Reconceiving Text Analysis: Toward an Algorithmic
		  Criticism},
  volume	= {18},
  issn		= {0268-1145, 1477-4615},
  url		= {http://llc.oxfordjournals.org/content/18/2/167},
  doi		= {10.1093/llc/18.2.167},
  shorttitle	= {Special Section},
  abstract	= {The inability of computing humanists to break into the
		  mainstream of literary critical scholarship may be
		  attributed to the prevalence of scientific methodologies
		  and metaphors in humanities computing
		  research—methodologies and metaphors that are wholly
		  foreign not only the language of literary criticism, but to
		  its entire purpose. Breaking out of this unfortunate
		  misalignment entails reaching for more appropriate
		  paradigms. The ‘algorithmic criticism’ here proposed
		  rejects the empiricist vision of the computer as a means by
		  which critical interpretations may be verified, and instead
		  seeks to locate computational processes within the rich
		  tradition of interpretive endeavours (usually aligned more
		  with art than criticism), which seek not to constrain
		  meaning, but to guarantee its multiplicity. Computational
		  processes, which are perhaps more conformable to this
		  latter purpose, may be usefully viewed as ways of providing
		  the necessary conditions for interpretive insight.
		  Algorithmic criticism seeks, therefore, in the narrowing
		  forces of constraint embodied and instantiated in the
		  strictures of algorithmic processing, an analogue to the
		  liberating potentialities of art and the ludic values of
		  humanistic inquiry. It proposes that we reconceive
		  computer‐assisted text analysis as an activity best
		  employed not in the service of a heightened critical
		  objectivity, but as one that embraces the possibilities of
		  that deepened subjectivity upon which critical insight
		  depends.},
  pages		= {167--174},
  number	= {2},
  journaltitle	= {Literary and Linguistic Computing},
  shortjournal	= {Lit Linguist Computing},
  author	= {Ramsay, Stephen},
  urldate	= {2016-08-17},
  date		= {2003-06-01},
  langid	= {english},
  file		= {Ramsay - 2003 - Reconceiving Text Analysis Toward an
		  Algorithmic
		  .pdf:/Users/lmullen/Zotero/storage/I2MIUEUP/Ramsay - 2003 -
		  Reconceiving Text Analysis Toward an Algorithmic
		  .pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/U3Z8XB7Z/167.html:text/html}
}

@InCollection{	  ramsayalgorithmiccriticism2008,
  address	= {Oxford},
  edition	= {Hardcover},
  series	= {Blackwell Companions to Literature and Culture},
  title		= {Algorithmic {{Criticism}}},
  isbn		= {978-1-4051-4864-1},
  lccn		= {0004},
  booktitle	= {Companion to {{Digital Literary Studies}}},
  publisher	= {{Blackwell Publishing Professional}},
  author	= {Ramsay, Stephen},
  month		= dec,
  year		= {2008}
}

@Article{	  ridgecreatingdeepmaps2013,
  title		= {Creating {{Deep Maps}} and {{Spatial Narratives}} through
		  {{Design}}},
  volume	= {7},
  doi		= {10.3366/ijhac.2013.0088},
  abstract	= {An interdisciplinary team of researchers were challenged
		  to create a model of a deep map during a three-day charette
		  at the NEH Institute on Spatial Narratives and Deep Maps.
		  Through a reflexive process of ingesting data, probing for
		  fruitful research questions, and considering how a deep map
		  might be used by different audiences, we created a
		  wireframe model of a deep map and explored how it related
		  to spatial narratives. We explored the tension between
		  interfaces for exploratory and structured views of data and
		  sources, and devised a model for the intersections between
		  spatial narratives and deep maps. The process of creating
		  wireframes and prototype screens\textemdash{} and more
		  importantly, the discussions and debates they
		  initiated\textemdash{}helped us understand the complex
		  requirements for deep maps and showed how a deep map can
		  support a humanistic interpretation of the role of space in
		  historical processes.},
  number	= {1},
  journal	= {International Journal of Humanities and Arts Computing},
  author	= {Ridge, Mia and Lafreniere, Don and Nesbit, Scott},
  year		= {2013},
  pages		= {176--189},
  file		= {/Users/jasonheppler/Dropbox/research-papers/Ridge et
		  al_2013_Creating Deep Maps and Spatial Narratives through
		  Design.pdf}
}

@InCollection{	  robertson_differences_2016,
  title		= {The Differences between Digital Humanities and Digital
		  History},
  url		= {http://dhdebates.gc.cuny.edu/debates/text/76},
  pages		= {289--307},
  booktitle	= {Debates in the Digital Humanities 2016},
  publisher	= {University of Minnesota Press},
  author	= {Robertson, Stephen},
  editor	= {Gold, Matthew K. and Klein, Lauren F.},
  date		= {2016}
}

@Article{	  robertson_searching_2016,
  title		= {Searching for Anglo-American Digital Legal History},
  volume	= {34},
  issn		= {1939-9022},
  doi		= {10.1017/S0738248016000389},
  number	= {4},
  journaltitle	= {Law and History Review},
  author	= {Robertson, Stephen},
  urldate	= {2016-08-26},
  date		= {2016-08},
  file		= {Cambridge Journals
		  Snapshot:/Users/lmullen/Zotero/storage/3T3G44IZ/displayAbstract.html:text/html}
}

@Article{	  robertson_signs_1998,
  title		= {Signs, Marks, and Private Parts: Doctors, Legal
		  Discourses, and Evidence of Rape in the United States,
		  1823-1930},
  volume	= {8},
  issn		= {1043-4070},
  url		= {http://www.jstor.org/stable/3704870},
  shorttitle	= {Signs, Marks, and Private Parts},
  pages		= {345--388},
  number	= {3},
  journaltitle	= {Journal of the History of Sexuality},
  shortjournal	= {Journal of the History of Sexuality},
  author	= {Robertson, Stephen},
  urldate	= {2016-06-30},
  date		= {1998},
  file		= {Robertson - 1998 - Signs, Marks, and Private Parts
		  Doctors, Legal
		  Di.pdf:/Users/lmullen/Zotero/storage/GDZ8S4QR/Robertson -
		  1998 - Signs, Marks, and Private Parts Doctors, Legal
		  Di.pdf:application/pdf}
}

@Article{	  rosenzweig_so_1995,
  title		= {`{{So}}, {{What}}'s {{Next}} for {{Clio}}?' {{CD}}-{{ROM}}
		  and {{Historians}}},
  volume	= {81},
  shorttitle	= {`{{So}}, {{What}}'s {{Next}} for {{Clio}}?},
  number	= {4},
  journal	= {The Journal of American History},
  author	= {Rosenzweig, Roy},
  month		= mar,
  year		= {1995},
  pages		= {1621--1640}
}

@Article{	  rosenzweigcrashingsystemhypertext1999,
  title		= {Crashing the {{System}}? {{Hypertext}} and {{Scholarship}}
		  on {{American Culture}}},
  volume	= {51},
  lccn		= {0006},
  number	= {2},
  journal	= {American Quarterly},
  author	= {Rosenzweig, Roy},
  month		= jun,
  year		= {1999},
  pages		= {237--246}
}

@Article{	  rosenzweigroadxanadupublic2001,
  title		= {The {{Road}} to {{Xanadu}}: {{Public}} and {{Private
		  Pathways}} on the {{History Web}}},
  volume	= {88},
  lccn		= {0032},
  number	= {2},
  journal	= {Journal of American History},
  author	= {Rosenzweig, Roy},
  month		= sep,
  year		= {2001},
  pages		= {548--579}
}

@Article{	  rosenzweigscarcityabundancepreserving2003a,
  title		= {Scarcity or {{Abundance}}? {{Preserving}} the {{Past}} in
		  a {{Digital Era}}},
  volume	= {108},
  issn		= {00028762},
  lccn		= {0044},
  shorttitle	= {Scarcity or {{Abundance}}?},
  doi		= {10.2307/3523084},
  number	= {3},
  journal	= {The American Historical Review},
  author	= {Rosenzweig, Roy},
  month		= jun,
  year		= {2003},
  pages		= {735--762},
  note		= {ArticleType: primary\_article / Full publication date:
		  Jun., 2003 / Copyright \textcopyright{} 2003 American
		  Historical Association}
}

@Article{	  rosenzweigwhatnextclio1995a,
  title		= {'{{So}}, {{What}}'s {{Next}} for {{Clio}}?' {{CD}}-{{ROM}}
		  and {{Historians}}},
  volume	= {81},
  lccn		= {0008},
  number	= {4},
  journal	= {Journal of American History},
  author	= {Rosenzweig, Roy},
  month		= mar,
  year		= {1995},
  pages		= {1621--1640}
}

@Article{	  rosner_teaching_1990,
  title		= {Teaching {{Quantitative History}} with a {{Database}}},
  journal	= {Perspectives on History},
  author	= {Rosner, Lisa},
  month		= oct,
  year		= {1990}
}

@Article{	  schmidt_language_2015,
  title		= {The Language of the State of the Union},
  issn		= {1072-7825},
  url		= {http://www.theatlantic.com/politics/archive/2015/01/the-language-of-the-state-of-the-union/384575/},
  abstract	= {An interactive chart reveals how the words presidents use
		  reflect the twists and turns of American history.},
  journaltitle	= {The Atlantic},
  author	= {Schmidt, Benjamin and Fraas, Mitch},
  urldate	= {2016-08-26},
  date		= {2015-01-18},
  file		= {The Atlantic
		  Snapshot:/Users/lmullen/Zotero/storage/73I294RI/384575.html:text/html}
}

@Article{	  sculley_meaning_2008,
  title		= {Meaning and mining: the impact of implicit assumptions in
		  data mining for the humanities},
  volume	= {23},
  url		= {http://llc.oxfordjournals.org/content/23/4/409.short},
  shorttitle	= {Meaning and mining},
  pages		= {409--424},
  number	= {4},
  journaltitle	= {Literary and Linguistic Computing},
  author	= {Sculley, D. and Pasanek, Bradley M.},
  urldate	= {2016-08-26},
  date		= {2008},
  file		= {[PDF]
		  psu.edu:/Users/lmullen/Zotero/storage/FER8JQKW/Sculley and
		  Pasanek - 2008 - Meaning and mining the impact of implicit
		  assumpt.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/XV24DGS7/409.html:text/html}
}

@Article{	  shapiro_quantitative_1973,
  title		= {Quantitative {{Studies}} of the {{French Revolution}}},
  volume	= {12},
  issn		= {0018-2656},
  doi		= {10.2307/2504909},
  number	= {2},
  journal	= {History and Theory},
  author	= {Shapiro, Gilbert and Markoff, John and Weitman, Sasha R.},
  year		= {1973},
  pages		= {163--191}
}

@Article{	  shmueli_explain_2010,
  title		= {To Explain or to Predict?},
  volume	= {25},
  issn		= {0883-4237, 2168-8745},
  url		= {http://projecteuclid.org/euclid.ss/1294167961},
  doi		= {10.1214/10-STS330},
  abstract	= {Statistical modeling is a powerful tool for developing and
		  testing theories by way of causal explanation, prediction,
		  and description. In many disciplines there is
		  near-exclusive use of statistical modeling for causal
		  explanation and the assumption that models with high
		  explanatory power are inherently of high predictive power.
		  Conflation between explanation and prediction is common,
		  yet the distinction must be understood for progressing
		  scientific knowledge. While this distinction has been
		  recognized in the philosophy of science, the statistical
		  literature lacks a thorough discussion of the many
		  differences that arise in the process of modeling for an
		  explanatory versus a predictive goal. The purpose of this
		  article is to clarify the distinction between explanatory
		  and predictive modeling, to discuss its sources, and to
		  reveal the practical implications of the distinction to
		  each step in the modeling process.},
  pages		= {289--310},
  number	= {3},
  journaltitle	= {Statistical Science},
  shortjournal	= {Statist. Sci.},
  author	= {Shmueli, Galit},
  urldate	= {2016-08-26},
  date		= {2010-08},
  mrnumber	= {MR2791669},
  keywords	= {causality, data mining, Explanatory modeling, predictive
		  modeling, predictive power, scientific research,
		  statistical strategy},
  file		= {Shmueli - 2010 - To Explain or to
		  Predict.pdf:/Users/lmullen/Zotero/storage/CSK2MBRH/Shmueli
		  - 2010 - To Explain or to
		  Predict.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/BESRUX6F/1294167961.html:text/html}
}

@Book{		  shotts_linux_2016,
  edition	= {3rd internet ed.},
  title		= {The Linux Command Line},
  url		= {http://linuxcommand.org/tlcl.php},
  publisher	= {No Starch Press},
  author	= {Shotts, William},
  date		= {2016},
  file		= {Shotts - 2016 - The Linux Command
		  Line.pdf:/Users/lmullen/Zotero/storage/8JHMWBB7/Shotts -
		  2016 - The Linux Command Line.pdf:application/pdf}
}

@Book{		  silge_tidy_2016,
  title		= {Tidy Text Mining in R},
  url		= {http://tidytextmining.com/},
  author	= {Silge, Julia and Robinson, David},
  date		= {2016}
}

@Article{	  simpson_rise_1981,
  title		= {The Rise and Fall of the Legal Treatise: Legal Principles
		  and the Forms of Legal Literature},
  volume	= {48},
  issn		= {0041-9494},
  url		= {http://www.jstor.org/stable/1599330},
  doi		= {10.2307/1599330},
  shorttitle	= {The Rise and Fall of the Legal Treatise},
  pages		= {632--679},
  number	= {3},
  journaltitle	= {The University of Chicago Law Review},
  shortjournal	= {The University of Chicago Law Review},
  author	= {Simpson, A. W. B.},
  urldate	= {2016-08-25},
  date		= {1981},
  file		= {Simpson - 1981 - The Rise and Fall of the Legal Treatise
		  Legal
		  Pri.pdf:/Users/lmullen/Zotero/storage/EK4UDIKT/Simpson -
		  1981 - The Rise and Fall of the Legal Treatise Legal
		  Pri.pdf:application/pdf}
}

@InCollection{	  sinclair_text_2016,
  title		= {Text Analysis and Visualization: Making Meaning Count},
  pages		= {274--90},
  booktitle	= {A New Companion to the Digital Humanities},
  publisher	= {Wiley Blackwell},
  author	= {Sinclair, Stéfan and Rockwell, Geoffrey},
  editor	= {Schreibman, Susan and Siemens, Ray and Unsworth, John},
  date		= {2016}
}

@Article{	  smith_computational_2015,
  title		= {Computational Methods for Uncovering Reprinted Texts in
		  Antebellum Newspapers},
  volume	= {27},
  issn		= {0896-7148, 1468-4365},
  url		= {http://alh.oxfordjournals.org/content/27/3/E1},
  doi		= {10.1093/alh/ajv029},
  pages		= {E1--E15},
  number	= {3},
  journaltitle	= {American Literary History},
  shortjournal	= {Am Lit Hist},
  author	= {Smith, David A. and Cordell, Ryan and Mullen, Abby},
  urldate	= {2016-08-25},
  date		= {2015-09-01},
  langid	= {english},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/THHKR6XB/E1.html:text/html}
}

@InProceedings{	  smith_detecting_2014,
  title		= {Detecting and modeling local text reuse},
  url		= {http://dl.acm.org/citation.cfm?id=2740800},
  pages		= {183--192},
  booktitle	= {Proceedings of the 14th {ACM}/{IEEE}-{CS} Joint Conference
		  on Digital Libraries},
  publisher	= {{IEEE} Press},
  author	= {Smith, David A. and Cordell, Ryan and Dillon, Elizabeth
		  Maddock and Stramp, Nick and Wilkerson, John},
  urldate	= {2015-11-08},
  date		= {2014},
  file		= {[PDF] from
		  neu.edu:/Users/lmullen/Zotero/storage/QI7BTZIA/Smith et al.
		  - 2014 - Detecting and modeling local text
		  reuse.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/QI56RZSE/citation.html:text/html}
}

@Misc{		  smithrumseyreportscholarlycommunication2010,
  title		= {Report of the {{Scholarly Communication Institute}} 8:
		  {{Emerging Genres}} in {{Scholarly Communication}}},
  publisher	= {{Scholarly Communication Institute, University of Virginia
		  Library}},
  author	= {Smith Rumsey, Abby},
  month		= jul,
  year		= {2010}
}

@Book{		  staleycomputersvisualizationhistory2002c,
  title		= {Computers, {{Visualization}}, and {{History}}: {{How New
		  Technology Will Transform Our Understanding}} of the
		  {{Past}}},
  isbn		= {0-7656-1095-7},
  lccn		= {0031},
  shorttitle	= {Computers, {{Visualization}}, and {{History}}},
  publisher	= {{M.E. Sharpe}},
  author	= {Staley, David J.},
  year		= {2002}
}

@Article{	  swierenga_clio_1970,
  title		= {Clio and {{Computers}}: {{A Survey}} of {{Computerized
		  Research}} in {{History}}},
  volume	= {5},
  issn		= {0010-4817, 1572-8412},
  shorttitle	= {Clio and {{Computers}}},
  doi		= {10.1007/BF02404252},
  number	= {1},
  journal	= {Computers and the Humanities},
  author	= {Swierenga, Robert P.},
  month		= sep,
  year		= {1970},
  pages		= {1--21},
  note		= {ArticleType: research-article / Issue Title: Annual Survey
		  of Recent Developments / Full publication date: Sep., 1970
		  / Copyright \textcopyright{} 1970 Springer}
}

@Article{	  swierengacliocomputerssurvey1970a,
  title		= {Clio and {{Computers}}: {{A Survey}} of {{Computerized
		  Research}} in {{History}}},
  volume	= {5},
  copyright	= {Copyright \textcopyright{} 1970 Springer},
  issn		= {0010-4817},
  shorttitle	= {Clio and {{Computers}}},
  doi		= {10.2307/30204000},
  number	= {1},
  journal	= {Computers and the Humanities},
  author	= {Swierenga, Robert P.},
  month		= sep,
  year		= {1970},
  pages		= {1--21},
  file		= {/Users/jheppler/Zotero/storage/A5SX9SRT/Swierenga - 1970 -
		  Clio and Computers A Survey of Computerized Resea.pdf},
  note		= {ArticleType: research-article / Issue Title: Annual Survey
		  of Recent Developments / Full publication date: Sep., 1970
		  / Copyright \textcopyright{} 1970 Springer}
}

@Article{	  tebeaulisteningcityoral2013,
  title		= {Listening to the {{City}}: {{Oral History}} and {{Place}}
		  in the {{Digital Era}}},
  volume	= {40},
  shorttitle	= {Listening to the {{City}}},
  doi		= {10.1093/ohr/oht037},
  abstract	= {This essay explores the development of a mobile
		  interpretive project, Cleveland Historical, that draws on
		  oral history theory and practice to emphasize aurality as a
		  key element in digital (and especially mobile) interpretive
		  projects. Developed at the intersection of oral history and
		  digital humanities theory and practice, Cleveland
		  Historical suggests a model of curation that emphasizes a
		  dynamic, layered, and contextual storytelling endeavor. The
		  resulting curato- rial process transforms the landscape
		  into a living museum, one in which the community actively
		  participates in remaking understandings of place and
		  community identity. Of particular note, this collaborative
		  oral history project provides a transformative way of
		  understanding ``place'' and of moving beyond an emphasis on
		  visual interpretive practice, in order to provide a deeper
		  way of building interpretive stories for public humanities
		  exhibitions on mobile com- puting devices.},
  number	= {1},
  journal	= {Oral History Review},
  author	= {Tebeau, Mark},
  year		= {2013},
  pages		= {25--35},
  file		= {/Users/jasonheppler/Dropbox/research-papers/Tebeau_2013_Listening
		  to the City.pdf}
}

@InCollection{	  theibault2013visualizations,
  title		= {Visualizations and {{Historical Arguments}}},
  journal	= {Writing History in the Digital Age},
  author	= {Theibault, John},
  year		= {2013},
  pages		= {173--185}
}

@InCollection{	  thomas_computing_2004,
  title		= {Computing and the {{Historical Imagination}}},
  copyright	= {Copyright \textcopyright{} 2004 by Blackwell Publishing
		  Ltd},
  isbn		= {978-0-470-99987-5},
  language	= {en},
  booktitle	= {A {{Companion}} to {{Digital Humanities}}},
  publisher	= {{Blackwell Publishing Ltd}},
  author	= {Thomas, William G.},
  editor	= {Schreibman, Susan and Siemens, Ray and Unsworth, John},
  year		= {2004},
  keywords	= {debates,historical imagination,historical
		  thinking,mathematical equation,social science},
  pages		= {56--68}
}

@Article{	  tilly_computers_1973,
  title		= {Computers in {{Historical Analysis}}},
  volume	= {7},
  abstract	= {The article describes the effect of computers on
		  historical analysis. He argues that computers reduce the
		  time necessary for collecting and matching historical data,
		  but that there is also an underlying danger. The increased
		  ease in which researchers can make post hoc statements
		  regarding spurious results may lead to mindless
		  empiricism.},
  number	= {6},
  journal	= {Computers and the Humanities},
  author	= {Tilly, Charles},
  year		= {1973},
  pages		= {323--335}
}

@Article{	  turchin_toward_2011,
  title		= {Toward {{Cliodynamics}} - an {{Analytical}}, {{Predictive
		  Science}} of {{History}}},
  volume	= {1},
  number	= {2},
  journal	= {Cliodynamics},
  author	= {Turchin, Peter},
  year		= {2011},
  keywords	= {Geopolitics,friction,Clausewitz,Modeling,military,military
		  transformation,organizational breakdown,victory}
}

@Article{	  underwood_literary_2015,
  title		= {The literary uses of high-dimensional space},
  volume	= {2},
  rights	= {© The Author(s) 2015},
  issn		= {2053-9517},
  url		= {http://bds.sagepub.com/content/2/2/2053951715602494},
  doi		= {10.1177/2053951715602494},
  abstract	= {Debates over “Big Data” shed more heat than light in
		  the humanities, because the term ascribes new importance to
		  statistical methods without explaining how those methods
		  have changed. What we badly need instead is a conversation
		  about the substantive innovations that have made
		  statistical modeling useful for disciplines where, in the
		  past, it truly wasn’t. These innovations are partly
		  technical, but more fundamentally expressed in what Leo
		  Breiman calls a new “culture” of statistical modeling.
		  Where 20th-century methods often required humanists to
		  squeeze our unstructured texts, sounds, or images into some
		  special-purpose data model, new methods can handle
		  unstructured evidence more directly by modeling it in a
		  high-dimensional space. This opens a range of research
		  opportunities that humanists have barely begun to discuss.
		  To date, topic modeling has received most attention, but in
		  the long run, supervised predictive models may be even more
		  important. I sketch their potential by describing how
		  Jordan Sellers and I have begun to model poetic distinction
		  in the long 19th century—revealing an arc of gradual
		  change much longer than received literary histories would
		  lead us to expect.},
  pages		= {2053951715602494},
  number	= {2},
  journaltitle	= {Big Data \& Society},
  author	= {Underwood, Ted},
  urldate	= {2016-08-26},
  date		= {2015-12-01},
  langid	= {english},
  file		= {Full Text
		  PDF:/Users/lmullen/Zotero/storage/IQ7E9UUZ/Underwood - 2015
		  - The literary uses of high-dimensional
		  space.pdf:application/pdf;Snapshot:/Users/lmullen/Zotero/storage/PPRQXB7X/2053951715602494.html:text/html}
}

@Article{	  underwood_theorizing_2014,
  title		= {Theorizing Research Practices We Forgot to Theorize Twenty
		  Years Ago},
  volume	= {127},
  rights	= {© 2014 by The Regents of the University of California},
  issn		= {0734-6018, 1533-855X},
  url		= {http://rep.ucpress.edu/content/127/1/64},
  doi		= {10.1525/rep.2014.127.1.64},
  abstract	= {Quantitative methods have been central to the humanities
		  since scholars began relying on full-text search to map
		  archives. But the intellectual implications of search
		  technology are rendered opaque by humanists’ habit of
		  considering algorithms as arbitrary tools. To reflect more
		  philosophically, and creatively, on the hermeneutic options
		  available to us, humanists may need to converse with
		  disciplines that understand algorithms as principled
		  epistemological theories. We need computer science, in
		  other words, not as a source of tools but as a theoretical
		  interlocutor.},
  pages		= {64--72},
  number	= {1},
  journaltitle	= {Representations},
  author	= {Underwood, Ted},
  urldate	= {2016-08-26},
  date		= {2014-08-01},
  langid	= {english},
  file		= {Snapshot:/Users/lmullen/Zotero/storage/TH6P2ED4/64.html:text/html;Underwood
		  - 2014 - Theorizing Research Practices We Forgot to
		  Theoriz.pdf:/Users/lmullen/Zotero/storage/3QRJ4TH8/Underwood
		  - 2014 - Theorizing Research Practices We Forgot to
		  Theoriz.pdf:application/pdf}
}

@InProceedings{	  unsworth_what_2002,
  title		= {What is Humanities Computing and What is not?},
  url		= {http://computerphilologie.uni-muenchen.de/jg02/unsworth.html},
  author	= {Unsworth, John},
  urldate	= {2016-08-22},
  date		= {2002},
  file		= {Unsworth\: What is Humanities Computing and What is
		  not?:/Users/lmullen/Zotero/storage/IP5EV2XE/unsworth.html:text/html}
}

@Book{		  welke_law_2010,
  title		= {Law and the borders of belonging in the long nineteenth
		  century United States},
  isbn		= {978-0-521-76188-8 978-0-521-15225-9},
  shorttitle	= {Law and the Borders of Belonging},
  abstract	= {"For more than a generation, historians and legal scholars
		  have documented inequalities at the heart of American law
		  and daily life and exposed inconsistencies in the generic
		  category of "American citizenship." Welke draws on that
		  wealth of historical, legal, and theoretical scholarship to
		  offer a new paradigm of liberal selfhood and citizenship
		  from the founding of the United States through the 1920s.
		  Law and the Borders of Belonging questions understanding
		  this period through a progressive narrative of expanding
		  rights, revealing that it was characterized instead by a
		  sustained commitment to borders of belonging of liberal
		  selfhood, citizenship, and nation in which able white men's
		  privilege depended on the subject status of disabled
		  persons, racialized others, and women. Welke's conclusions
		  pose challenging questions about the modern liberal
		  democratic state that extend well beyond the temporal and
		  geographic boundaries of the long nineteenth century United
		  States"--Provided by publisher},
  pagetotal	= {239},
  publisher	= {Cambridge University Press},
  author	= {Welke, Barbara Young},
  date		= {2010},
  note		= {{OCLC}: ocn470360693},
  keywords	= {19th century, Discrimination, Equality, History, Law and
		  legislation History, United States}
}

@Misc{		  whitewhatspatialhistory,
  title		= {What Is {{Spatial History}}?},
  howpublished	= {http://www.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=29},
  journal	= {Spatial History Project},
  author	= {White, Richard}
}

@Book{		  wickham_advanced_2014,
  title		= {Advanced R},
  isbn		= {978-1-4665-8696-3},
  url		= {http://adv-r.had.co.nz/},
  abstract	= {An Essential Reference for Intermediate and Advanced R
		  Programmers Advanced R presents useful tools and techniques
		  for attacking many types of R programming problems, helping
		  you avoid mistakes and dead ends. With more than ten years
		  of experience programming in R, the author illustrates the
		  elegance, beauty, and flexibility at the heart of R. The
		  book develops the necessary skills to produce quality code
		  that can be used in a variety of circumstances. You will
		  learn: The fundamentals of R, including standard data types
		  and functions Functional programming as a useful framework
		  for solving wide classes of problems The positives and
		  negatives of metaprogramming How to write fast,
		  memory-efficient code This book not only helps current R
		  users become R programmers but also shows existing
		  programmers what’s special about R. Intermediate R
		  programmers can dive deeper into R and learn new strategies
		  for solving diverse problems while programmers from other
		  languages can learn the details of R and understand why R
		  works the way it does.},
  pagetotal	= {476},
  publisher	= {Chapman and Hall},
  author	= {Wickham, Hadley},
  date		= {2014-09-25}
}

@Book{		  wickham_r_2016,
  title		= {R for Data Science},
  isbn		= {978-1-4919-1039-9},
  url		= {http://r4ds.had.co.nz/},
  abstract	= {What exactly is data science? With this book, you’ll
		  gain a clear understanding of this discipline for
		  discovering natural laws in the structure of data. Along
		  the way, you’ll learn how to use the versatile R
		  programming language for data analysis.Whenever you measure
		  the same thing twice, you get two results—as long as you
		  measure precisely enough. This phenomenon creates
		  uncertainty and opportunity. Author Garrett Grolemund,
		  Master Instructor at {RStudio}, shows you how data science
		  can help you work with the uncertainty and capture the
		  opportunities. You’ll learn about:Data Wrangling—how to
		  manipulate datasets to reveal new {informationData}
		  Visualization—how to create graphs and other
		  {visualizationsExploratory} Data Analysis—how to find
		  evidence of relationships in your
		  {measurementsModelling}—how to derive insights and
		  predictions from your {dataInference}—how to avoid being
		  fooled by data analyses that cannot provide foolproof
		  {resultsThrough} the course of the book, you’ll also
		  learn about the statistical worldview, a way of seeing the
		  world that permits understanding in the face of
		  uncertainty, and simplicity in the face of complexity.},
  pagetotal	= {250},
  publisher	= {O'Reilly},
  author	= {Wickham, Hadley and Grolemund, Garrett},
  date		= {2016-12-25}
}

@Article{	  wilkens_digital_2015,
  title		= {Digital {{Humanities}} and {{Its Application}} in the
		  {{Study}} of {{Literature}} and {{Culture}}},
  volume	= {67},
  issn		= {0010-4124, 1945-8517},
  doi		= {10.1215/00104124-2861911},
  abstract	= {``Digital Humanities and Its Application in the Study of
		  Literature and Culture'' examines the relationship between
		  comparative literary and cultural studies, systems theory
		  and model building, and recent work in digital humanities.
		  Areas of specific application include the topology of
		  German literature, modernist poetics in China, Japan, and
		  the United States, and the geography of nineteenth-century
		  fiction, as well as a range of associated computational
		  methods. Wilkens argues that computational work represents
		  a unique opportunity for comparatists interested in
		  large-scale cultural analysis and that digital humanities
		  would benefit from increased participation by
		  comparatists.},
  language	= {en},
  number	= {1},
  journal	= {Comparative Literature},
  author	= {Wilkens, Matthew},
  month		= jan,
  year		= {2015},
  keywords	= {digital humanities,cultural studies,large-scale cultural
		  analysis,systems theory},
  pages		= {11--20}
}

@InCollection{	  witmore_text:_2012,
  title		= {Text: A Massively Addressable Object},
  url		= {http://dhdebates.gc.cuny.edu/debates/text/28},
  booktitle	= {Debates in the Digital Humanities 2012},
  publisher	= {University of Minnesota Press},
  author	= {Witmore, Michael},
  date		= {2012}
}

@Article{	  xu_detecting_2014,
  title		= {Detecting and Evaluating Local Text Reuse in Social
		  Networks},
  url		= {http://www.aclweb.org/website/old_anthology/W/W14/W14-27.pdf#page=62},
  pages		= {50},
  journaltitle	= {{ACL} 2014},
  author	= {Xu, Shaobin and Smith, David A. and Mullen, Abigail and
		  Cordell, Ryan},
  urldate	= {2015-11-09},
  date		= {2014},
  file		= {[PDF] from
		  aclweb.org:/Users/lmullen/Zotero/storage/M52UB4CJ/Xu et al.
		  - 2014 - Detecting and Evaluating Local Text Reuse in
		  Socia.pdf:application/pdf}
}
